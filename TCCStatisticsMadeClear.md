# Meaning from Data: Statistics Made Clear

#### Michael Starbird, Ph.D. 
##### Professor of Mathematics, The University of Texas at Austin 

## Lecture 1: Describing Data and Inferring Meaning 


Statistics is the study of **data**. It is a mode of reasoning that is used absolutely everywhere. 

It's really hard to find a place where statistics isn't important, not a place where it is. Starbird notes that at his university, the University of Texas at Austin, statistics is taught in nearly every department. 

The trouble with data is that data are really meaningless, or even misleading, if we just have data. The point is that data do not come with meaning.

"It is easy to lie with statistics, but it is easier to lie without them."
-Frederick Mosteller 

Our challenge in this course is to extract meaning from data, and to gather data that actually has meaning.

Statistics and Data - are these words plural or singular?

**Data** is the plural of **datum**, which is a single piece of information. So data is a collection of pieces of information. 

A **statistic** is a number computed from a sample. For example, if you say that 49% of people polled support a particular candidate, that is a statistic. 

We need to develop a collection of concepts, and a vocabulary, 


Statistics has two basic parts: 

1. How can we describe and extract meaning from a collection of data if we know all of the data in a collection.
2. How can we describe and extract meaning from an incomplete collection of data, where we don't have all the relevant information. How do we infer information about a population when we don't have data about the entire population.


Lectures two and three are an introduction to and analysis of statistics. Three covers statistical inferences, which is inferring from data about some members of a population, likely attributes of an entire population. 

Lecture eight discusses probability for inference. Eight to twelve then develop the concepts and logic of statistical inference. The concept of probability allows us to develop expectations, statistical expectations 

In lecture 9 we introduce the concept of a sample. We hope that when we take a sample, it mirrors or reflects what's happening in a general population. The goal is to get a sample that is representative of an entire population. There are a lot of pitfalls that need to be avoided when acquiring a sample that can be said to be representative. 

In lecture 11 we talk about the concept of a **confidence interval**. 

Lecture 12 talks about the design of experiments. If you're going to gather data, you need to think ahead about what kind of data you want to collect. Things like keeping other variables fixed, so we can focus on the one changing quantity we're trying to measure.

Lecture 13 kicks off the series of lectures on applications of statistics. 

In Lecture 17 we talk about risk, both in war and insurance.

In Lecture 18 we talk about real estate, where we introduce multiple regression.

In Lecture 19 we talk about misleading or lying in statistics.

In lecture 20 talk about statistics and social science, namely Myers-Briggs personality test.

In 21 we talk about pain and weight.

In 22 we talk about economics, including a way to detect whether there is fraud in a set of data. 

In 23 we talk about science.

In 24 we sum up the course with the conclusion that statistics will only increase in prominence and relevance, largely owing to the fact that computers can deal with large amounts of data. 


## Lecture 2: Data and Distributions - Getting the Big Picture 

**Data**. Statistics starts with data. 

How can we understand this ocean of numbers? That's the role of statistics. 

The world is full of tables of data. We're going to try to make sense of these lists by attempting to organize, describe, and summarize a set of data. Oftentimes the best way to do it is to create a **graphical representation**, an image. 

A good way to summarize data is to put it in one single number. The **mean** the average. One limitation of the mean is the fact that outliers may skew the results. 

**Mean** = the number obtained by adding all the numbers and dividing by their count. 

A different kind of a summary number may be more valuable, which could be the **median**, which is the middle number on the list. 

**Median** is the middle number of the list. It's the number obtained when you order the list, and take the middle number. The median is a center value, and like the mean, is a center value. It's a different concept of center. 

**First Quartile** is 25% of the way up. It's the value so that 25% of the data are <= to that value, and 75% are >= to that value. 

**Third Quartile** The value of the number of the list so that 75% of the values on the list are less than that list. is 75% of the way. It's the value so that 75% of the data are <= to value, and 25% are >= to that value/ 

***Five Number Summary*** that gives some sense of a whole data set. 

1. Minimum 
2. First Quartile
3. Median (essentially the second quartile)
4. Third Quartile 
5. Maximum (essentially the fourth quartile)

Q: How to obtain the FQ and TQ? 

- The whole question of statistics is: what measurement(s) to use to infer meaning from a particular dataset?
- The more specific and detailed your dataset, the more insightful the **Five Number Summary** is going to be. For example, instead of comparing all doctors to all doctors, compare subspecialities to subspecialties. Instead of comparing professors to professors, compare sociology professors to sociology professors, physics professors to physics professors and so on. 
- The mean is very useful when the values of the data are "tight" or close together 
- The median can be helpful when you have some outliers, or if the 

To create a histogram, you take the values of the variable you're measuring and divide them into groups. Then plot the groups as bars. It's a good way of getting some sense of the distribution of a dataset. 

You can find the 25% by asking the questions: What is the amount of rainfall on 25% of days? What is the gas mileage that 25% of cars on the parking lot have achieved. Likewise, the third quartile is the value so that 75% of days have less or equal to that much rainfall, or 75% of car    <-- //TODO: refactor this with better examples. 

A **distribution** is the fundamental idea of looking at a whole dataset. The distrubtion is summarized and takes on a shape by looking at the shape of the histogram (a bar graph). The distribution of a set of data is defined as the *values* that this variable takes (like salaries) and *how often* it takes them (frequency - how many people are paid that salary).  

One of the big lessons of this whole course is **don't rely on one number.**

Some types, or shapes, of distribution are **symettrical**, **bimodal**, and **skewed**. 

What we've come to are *three principles for organizing data*. 

1. **Shape**. Is it symettrical? Is it skewed to the left (towards the y axis) or towards the right (away from the y axis).
2. **Center**. 
3. **Spread**. How dispersed or, alternatively, how compacted the values are. 

Next, look at the **relationship** between two varying aspects of the same individuals in a population. For example a student's SAT score's relationship to his or her GPA in college. Or a salesperson's average wake time to their commission income. 

In summary, the basic way to get meaning from data when we have all the data of a population at interest involves the concept of the distribution, and the main aspects of the distribution that we lookeda t are it's shape, its center and its spread. Histograms and box plots are useful graphical aids, and quantities like the mean, median and quartiles are often used to easure or summarize the data but they don't preserve all of hte ifnormation. Data comes in different shapes, and some that we';; rum into often adn can decsvir mathematically. 

When we have associated data, we can visualize them by graphing a scatterplot, and we can sometimes approximate the rleationship wbetween these related data with a straight line. All of the concepts in these lectures will be quantified in future lectures, so this lecture's purspoe was to give mostly a qualitative view of methods of organizing, describing and summarizing data.  

Perhaps the first three rules of statistics should be:
1. Draw a picture
2. Draw a picture
3. and, Draw a picture 

In the next lecture, we'll introduce the concept of statistical inference, where we infer these features of a data set when we just know the values of *some* of the members of a population.   
  
 
## Lecture 3:  Inference - How Close? How Confident? 







































